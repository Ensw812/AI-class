import os, glob, re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
LEARNING_RATE = 0.05
EPOCHS = 1200
TEST_SIZE = 0.2

def standardize(X):
    mu = X.mean(axis=0, keepdims=True)
    sigma = X.std(axis=0, ddof=0, keepdims=True)
    sigma[sigma == 0] = 1.0
    return (X - mu) / sigma, mu, sigma

def add_bias(X):
    return np.hstack([np.ones((X.shape[0], 1)), X])

def mse_cost(X, y, theta):
    preds = X @ theta
    errors = preds - y
    return (errors @ errors) / (2 * len(y))

def r2_score(y_true, y_pred):
    ss_res = np.sum((y_true - y_pred)**2)
    ss_tot = np.sum((y_true - y_true.mean())**2)
    return 1 - ss_res/ss_tot if ss_tot != 0 else 0.0

def train_test_split(X, y, test_size=0.2, seed=42):
    n = len(y)
    idx = np.arange(n)
    rng = np.random.default_rng(seed)
    rng.shuffle(idx)
    test_n = int(round(n * test_size))
    test_idx = idx[:test_n]
    train_idx = idx[test_n:]
    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]

import kagglehub
ds_path = kagglehub.dataset_download("zafarali27/house-price-prediction-dataset")
csv_path = glob.glob(os.path.join(ds_path, "*.csv"))[0]
df = pd.read_csv(csv_path).dropna()

target_col = [c for c in df.columns if "price" in c.lower()][0]
possible_size = [c for c in df.columns if re.search(r'area|size|sqft|lot', c, re.I)]
possible_age  = [c for c in df.columns if re.search(r'age|year', c, re.I)]

if possible_size and possible_age:
    features = [possible_size[0], possible_age[0]]
else:
    num_cols = df.select_dtypes(include=[np.number]).columns
    corr = df[num_cols].corr()[target_col].drop(target_col).abs().sort_values(ascending=False)
    features = corr.head(2).index.tolist()

X_raw = df[features].to_numpy().astype(float)
y_raw = df[target_col].to_numpy().astype(float)

X, muX, stdX = standardize(X_raw)
y, muy, stdy = standardize(y_raw.reshape(-1,1))
y = y.reshape(-1,)

X_train, X_test, y_train, y_test = train_test_split(X, y, TEST_SIZE, RANDOM_SEED)
Xb_train, Xb_test = add_bias(X_train), add_bias(X_test)

theta = np.zeros(Xb_train.shape[1])
start_cost = mse_cost(Xb_train, y_train, theta)

print("Initial theta:", theta)
print("Learning rate:", LEARNING_RATE)
print("Epochs:", EPOCHS)
print("Start cost:", start_cost)

costs = []
snapshots = []
for epoch in range(1, EPOCHS+1):
    preds = Xb_train @ theta
    grad = (Xb_train.T @ (preds - y_train)) / len(y_train)
    theta -= LEARNING_RATE * grad
    if epoch % 50 == 0:
        costs.append(mse_cost(Xb_train, y_train, theta))
    if epoch in [1, 10, 50, 200, 600, 1200]:
        snapshots.append((theta.copy(), epoch))

final_cost = mse_cost(Xb_train, y_train, theta)
y_pred_train, y_pred_test = Xb_train @ theta, Xb_test @ theta

print("Final theta:", theta)
print("Final cost:", final_cost)
print("R² train:", r2_score(y_train, y_pred_train))
print("R² test:", r2_score(y_test, y_pred_test))

plt.plot(np.linspace(1, EPOCHS, len(costs)), costs)
plt.xlabel("Epoch"); plt.ylabel("Cost")
plt.title("Learning Curve")
plt.show()

plt.scatter(y_test, y_pred_test, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual"); plt.ylabel("Predicted")
plt.title("Predicted vs Actual (Test)")
plt.show()

x1, x2 = np.meshgrid(
    np.linspace(X[:,0].min(), X[:,0].max(), 20),
    np.linspace(X[:,1].min(), X[:,1].max(), 20)
)

for th, ep in snapshots:
    fig = plt.figure(figsize=(7,5))
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(X[:,0], X[:,1], y, c='blue', alpha=0.5)
    y_plane = th[0] + th[1]*x1 + th[2]*x2
    ax.plot_surface(x1, x2, y_plane, color='red', alpha=0.3)
    ax.set_xlabel(features[0] + " (std)")
    ax.set_ylabel(features[1] + " (std)")
    ax.set_zlabel("Price (std)")
    ax.set_title(f"Hypothesis at Epoch {ep}")
    plt.show()
